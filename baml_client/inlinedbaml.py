###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "answer_question.baml": "// Define a class to represent a structured context item\nclass ContextItem {\n  content string\n  source string? // Source/link is optional\n}\n\nclass Source {\n  index int\n  source string\n  source_type string\n}\n// AnswerQuestion: Compose a final answer using the question and structured context info\nclass Answer {\n  cited_answer string @description(\"The final answer with inline citations like [0], [1] referring to the context items.\")\n  // Updated references to be a list of strings\n  references Source[] @description(\"A numerical list of source URLs/identifiers corresponding to the citations used in the answer.\")\n}\n\n// Updated function signature to accept a list of ContextItem objects\nfunction AnswerQuestion(question: string, context: ContextItem[]) -> Answer {\n  client Gemini2FlashClient\n\n  prompt #\"\"\"\n    You are an expert writing a detailed answer to the user's question using the provided structured context information.\n    Use the context items to ensure accuracy and completeness.\n    **Cite the context items used for each part of your answer using bracketed numbers corresponding to the list below (e.g., [0], [1]).**\n    Integrate the information naturally. Do not just list the context content verbatim.\n    If the context contains a current price or specific data, include it in the answer with its citation.\n    After generating the `cited_answer`, list all the `source` fields from the context items you actually cited in the `references` field. Only include sources that were cited. If a cited item has no source, omit it from the references list.\n    The answer should fully address the question.\n\n    Question: {{ question }}\n\n    Context Items:\n    // Updated context loop to iterate over ContextItem objects and access their fields\n    {% for item in context %}\n    [{{ loop.index0 }}] Content: {{ item.content }}\n       Source: {{ item.source or \"N/A\" }}\n    {% endfor %}\n\n    ----\n    {{ ctx.output_format }}\n  \"\"\"#\n}\n\n// Tests for AnswerQuestion\ntest answer_with_general_context {\n  functions [AnswerQuestion]\n  args {\n    question \"How does photosynthesis work in plants?\"\n    context [\n      { \n        content \"Photosynthesis uses sunlight, water, and carbon dioxide to create glucose (sugar) and oxygen.\", \n        source \"http://example.com/photosynthesis-basics\" \n      },\n      { \n        content \"Chlorophyll, the green pigment in leaves, absorbs sunlight.\", \n        source \"http://example.com/chlorophyll-role\"\n      },\n      { \n        content \"The process primarily occurs in chloroplasts within plant cells.\", \n        source \"http://example.com/chloroplasts\" \n      },\n      { \n        content \"Oxygen is released as a byproduct.\", \n        source null // Example with no source\n      }\n    ]\n  }\n  @@assert({{ this.cited_answer != \"\"}})\n  @@assert({{ \"glucose\" in this.cited_answer or \"oxygen\" in this.cited_answer or \"chlorophyll\" in this.cited_answer }})\n  @@assert({{ \"[0]\" in this.cited_answer or \"[1]\" in this.cited_answer or \"[2]\" in this.cited_answer or \"[3]\" in this.cited_answer }})\n  // Check if references are generated correctly (at least the ones with sources)\n  @@assert({{ this.references | length >= 2 }})\n  @@assert({{ \"http://example.com/photosynthesis-basics\" in (this.references | map(attribute='source') | list) }})\n}\n",
    "clarify_question.baml": "class Clarification {\n  needed bool\n  question string\n}\n\nfunction ClarifyQuestion(question: string) -> Clarification {\n  client Gemini2FlashClient\n\n  prompt #\"\"\"\n    You are a helpful assistant analyzing a user query for clarity.\n    Determine if the query needs clarification. \n\n    If the query is sufficiently clear and specific, output:\n    - needed: false \n    - question: \"\"  (empty string)\n\n    If the query is ambiguous or missing details, output:\n    - needed: true \n    - question: a single, concise clarifying question to ask the user.\n\n    Make sure to follow the output format strictly.\n    \n    User Query: \"{{ question }}\"\n    ----\n    {{ ctx.output_format }}\n  \"\"\"#\n}\n\ntest clarify_no_clarification_needed {\n  functions [ClarifyQuestion]\n  args { question \"What is the capital of France?\" }\n  @@assert({{ this.needed == false }})\n  @@assert({{ this.question == \"\" }})\n}\n\ntest clarify_needs_clarification {\n  functions [ClarifyQuestion]\n  args { question \"Tell me about that recent discovery.\" }\n  @@assert({{ this.needed == true }})\n  @@assert({{ this.question|length > 5 }})\n  @@assert({{ this.question|regex_match(\"(?i)(discovery|which|what)\") }})\n}\n",
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> Gemini2FlashClient {\n  provider \"google-ai\"\n  options {\n    model \"gemini-2.0-flash\"\n    api_key env.GEMINI_API_KEY\n  }\n}\n\nclient<llm> Gemini2_5FlashClient {\n  provider \"google-ai\"\n  options {\n    model \"gemini-2.5-flash-preview-04-17\"\n    api_key env.GEMINI_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "critique_answer.baml": "// CritiqueAnswer: Verify the answer's quality and identify missing information if any\nclass Critique {\n  is_good bool\n  missing_info string\n}\n\nfunction CritiqueAnswer(question: string, answer: string) -> Critique {\n  client Gemini2FlashClient\n\n  prompt #\"\"\"\n    You are a critical evaluator of the assistant's answer.\n    Evaluate the answer against the question:\n    - If the answer is fully correct, addresses all parts of the question, and is sufficiently detailed, set is_good to true and missing_info to \"\".\n    - If something is missing, incorrect, or not thoroughly answered, set is_good to false and provide missing_info: a short phrase indicating what info is missing or needs correction (suitable for a search query). Do NOT write a full sentence, just keywords or a brief topic.\n\n    Question: \"{{ question }}\"\n    Answer: \"{{ answer }}\"\n    \n    {{ ctx.output_format }}\n  \"\"\"#\n}\n\n// Tests for CritiqueAnswer\ntest critique_complete_answer {\n  functions [CritiqueAnswer]\n  args { \n    question \"What is 2+2?\", \n    answer \"2+2 is 4.\" \n  }\n  @@assert({{ this.is_good == true }})\n  @@assert({{ this.missing_info == \"\" }})\n}\n\ntest critique_incomplete_answer {\n  functions [CritiqueAnswer]\n  args { \n    question \"What are the benefits and risks of Bitcoin?\", \n    answer \"Bitcoin's benefits include decentralization and fast transactions.\" \n  }\n  // The answer did not cover risks, expect critique to flag missing info about risks\n  @@assert({{ this.is_good == false }})\n  @@assert({{ \"risk\" in this.missing_info | lower() }})\n}\n\ntest critique_incomplete_general_answer {\n  functions [CritiqueAnswer]\n  args { \n    question \"Describe the water cycle, including evaporation and precipitation.\", \n    answer \"The water cycle involves water evaporating from the surface due to heat.\" \n  }\n  // The answer only mentioned evaporation, not precipitation. Expect critique to flag missing info about precipitation.\n  @@assert({{ this.is_good == false }})\n  @@assert({{ \"precipitation\" in this.missing_info | lower() or \"rainfall\" in this.missing_info | lower() }})\n}\n",
    "filter_results.baml": "// Define the structure for a raw result/observation item\n// Matches the format produced by execute_tool_node\nclass ObservationItem {\n  content string?\n  link string?\n  error string? // Include error field if tools can return errors\n}\n\n// Define the structure for a filtered, relevant result item\n// This is what will be accumulated in the state\nclass FilteredItem {\n  content string\n  source string? // Use 'source' to align with AnswerQuestion context\n}\n\n// Function to filter raw observations for relevance\nfunction FilterResults(\n  question: string,\n  results: ObservationItem[] // Takes a list, even if usually just one observation\n) -> FilteredItem[] { // Returns a list of relevant items\n\n  client Gemini2FlashClient // Use a fast and capable client\n\n  prompt #\"\nYou are an information filter. Your task is to analyze the provided observation(s) based on their relevance to the original user question.\n\nUser Question: \"{{ question }}\"\n\nObservation(s) to Filter:\n{% for item in results %}\n--- Observation {{ loop.index0 }} ---\n{% if item.content %}Content: {{ item.content }}{% endif %}\n{% if item.link %}Link: {{ item.link }}{% endif %}\n{% if item.error %}Error: {{ item.error }}{% endif %}\n{% if not item.content and not item.link and not item.error %} [Empty Observation] {% endif %}\n--- End Observation {{ loop.index0 }} ---\n{% endfor %}\n\nInstructions:\n1. Evaluate each observation's content (or error message) for direct relevance to answering the user's question.\n2. Ignore observations that are errors unrelated to the question (e.g., API timeouts) or content that is clearly off-topic.\n3. For relevant observations:\n    - Extract the core information relevant to the question from the 'content' field. Summarize slightly if necessary, but retain key facts/data.\n    - Use the 'link' field as the 'source' if available. If there's an error message that *is* relevant (e.g., \"Price not found for XYZ coin\"), use the error message as the content and set source to null.\n4. Return ONLY the relevant items as a list of FilteredItem objects.\n5. If NO observations are relevant, return an empty list: [].\n\nOutput ONLY the list of FilteredItem objects.\n\n{{ ctx.output_format }}\n\"#\n}\n\n// Test case: Relevant content\ntest FilterRelevantContent {\n  functions [FilterResults]\n  args {\n    question \"What is the price of Bitcoin?\"\n    results [\n      { \n        content \"The current price of Bitcoin is $65,000.\"\n        link \"http://price-api.com/btc\" \n      }\n    ]\n  }\n  @@assert( {{ this | length == 1 }} )\n  @@assert( {{ \"$65,000\" in this[0].content }} )\n  @@assert( {{ this[0].source == \"http://price-api.com/btc\" }} )\n}\n\n// Test case: Irrelevant content\ntest FilterIrrelevantContent {\n  functions [FilterResults]\n  args {\n    question \"What is the price of Bitcoin?\"\n    results [\n      { \n        content \"Ethereum is a popular altcoin.\"\n        link \"http://crypto-info.com/eth\" \n      }\n    ]\n  }\n  @@assert( {{ this | length == 0 }} ) // Expect empty list\n}\n\n// Test case: Relevant error\ntest FilterRelevantError {\n  functions [FilterResults]\n  args {\n    question \"What is the price of NonExistentCoin?\"\n    results [\n      { \n        error \"Could not find price data for NonExistentCoin\" \n      }\n    ]\n  }\n   @@assert( {{ this | length == 1 }} )\n   @@assert( {{ \"Could not find price data\" in this[0].content }} )\n   @@assert( {{ this[0].source == null }} )\n}\n\n// Test case: Irrelevant error\ntest FilterIrrelevantError {\n  functions [FilterResults]\n  args {\n    question \"What is the price of Bitcoin?\"\n    results [\n      { \n        error \"API connection timeout\" \n      }\n    ]\n  }\n   @@assert( {{ this | length == 0 }} ) // Expect empty list\n}\n\n// Test case: Mixed results\ntest FilterMixedResults {\n  functions [FilterResults]\n  args {\n    question \"Compare Bitcoin and Ethereum prices.\"\n    results [\n      { \n        content \"Bitcoin price: $65,000\"\n        link \"http://price.com/btc\" \n      }\n      { \n        content \"Ethereum price: $3,500\"\n        link \"http://price.com/eth\" \n      }\n      { \n        content \"Solana is fast.\"\n        link \"http://sol.com\" \n      }\n    ]\n  }\n  @@assert( {{ this | length == 2 }} ) // Expect BTC and ETH results\n  @@assert( {{ this | map(attribute='source') | contains(\"http://price.com/btc\") }} )\n  @@assert( {{ this | map(attribute='source') | contains(\"http://price.com/eth\") }} )\n} ",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.86.1\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "reason_act.baml": "// Define the available tools as an enum\n// Ensure these names match the keys used in the execute_tool_node in graph.py\nenum ToolName {\n  WebSearch\n  PriceLookup\n  AddressTracker\n  OnChainMetrics\n  UrlExtractor\n}\n\n// Define the output structure for the agent's action\n// This should match the AgentAction class in agents/deep_research/state.py\nclass AgentAction {\n  tool_name ToolName? // Tool to use, null if finishing\n  query string?       // Query for the tool, null if finishing\n  finish bool         // True if the agent should stop searching and generate an answer\n  thought string      // The reasoning process leading to this action/decision\n}\n\n// Define an input structure for history items\nclass HistoryItem {\n  thought string\n  action string // Summary of the previous action (e.g., \"WebSearch('AI fairness')\")\n  observation string // Summary of the *filtered* observation from the action\n}\n\n// The main reasoning function\nfunction ReasonAct(\n  question: string,\n  clarification_details: string?,\n  history: HistoryItem[],\n  critique_feedback: string? // Added input for critique feedback\n) -> AgentAction {\n  // Use your preferred LLM client that supports function calling/structured output\n  // Ensure the client is configured in your BAML project settings\n  client Gemini2FlashClient // Example client\n\n  prompt #\"\nYou are a helpful research assistant following the ReAct framework (Reason, Act, Observe). Your goal is to answer the user's question thoroughly by reasoning about the required information, acting by selecting the appropriate tool, and observing the filtered results from the tool execution.\n\nUser Question: {{question}}\n{% if clarification_details %}\nUser Clarification: {{clarification_details}}\n{% endif %}\n\nAvailable Tools:\n- WebSearch(query: string): Searches the web for general knowledge, recent events, opinions, or specific documents. Returns snippets and links.\n- PriceLookup(coin_name: string): Gets the current price of a cryptocurrency (e.g., 'bitcoin', 'ethereum', 'solana'). Returns the price string (e.g., '$65000.00') or an error.\n- AddressTracker(query: string): Tracks recent large transactions for a specific blockchain address. Query format: 'chain:address' (e.g., 'eth:0x123...', 'sol:abc...', 'btc:bc1q...'). Returns a summary of activity or an error.\n- OnChainMetrics(asset_name: string): Gets recent on-chain metrics (like active addresses, transaction count) for an asset (e.g., 'btc', 'eth', 'sol'). Returns a data summary or an error.\n- UrlExtractor(url: string): Extracts the main text content from a given URL. Use this *after* a WebSearch finds a promising link. Returns the extracted text or an error.\n\nReAct History (Thought -> Action -> Filtered Observation):\n{% for item in history %}\nThought: {{ item.thought }}\nAction: {{ item.action }}\nObservation: {{ item.observation }}\n---\n{% endfor %}\n\n{% if critique_feedback %}\nCritique Feedback from Last Attempt:\n\"{{ critique_feedback }}\"\n**You MUST prioritize addressing this feedback in your next action.** Analyze the critique and decide how to best gather the missing information or correct the previous approach using the available tools.\n{% endif %}\n\nCurrent Task: Based on the original question, the history, and **especially any critique feedback provided**, decide the next best action.\n\nYour thought process should be:\n1. Analyze the original question, the information gathered so far (history), and **critically evaluate any critique feedback**.\n2. If critique feedback exists: Determine the core issue (e.g., missing data point, wrong comparison, insufficient detail). Select the best tool and formulate a query to *directly address* that critique.\n3. If no critique feedback: Identify the *most important* piece of missing information needed to answer the original question comprehensively based on the current history.\n4. Choose the *single best tool* from the available list to acquire that specific piece of information. Formulate a precise and effective query for the chosen tool.\n5. If you are confident that you have gathered sufficient information (considering the history and having addressed any critique) to construct a complete and accurate final answer, decide to finish. Avoid redundant tool calls unless necessary to get updated information (like price).\n\nOutput Format:\nProvide your step-by-step reasoning in the 'thought' field. Explain *why* you are choosing a specific tool/query or deciding to finish, referencing the history and critique feedback as needed.\nThen, specify the 'tool_name' and 'query' if taking an action.\nSet 'finish' to true ONLY if you are ready to generate the final answer. Otherwise, set 'finish' to false.\n\nThought: (Your reasoning here...)\nAction: (Set tool_name/query OR set finish=true)\n\"\"\"#\n}\n",
}

def get_baml_files():
    return file_map